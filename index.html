<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>APHM</title>
        <link rel="stylesheet" href="style.css">
    </head>
    <body>
        <div id="particles-js" style="position:absolute;width: 100%; height: 100%;">
            <canvas class="particles-js-canvas-el" width="1583" height="497" style="width: 100%; height: 100%;"></canvas>
        </div>
        <br><br>
        <div id="outer_container" style="width: 70%; margin: auto;">
            <div id="title_author" class="" style="font-family:Verdana;text-align:center;font-color:white;padding:1em;position:relative;background:white;border-radius:1em;">
                            <h3 style="margin-top: 1em;margin-bottom: 1em;margin-left: 0;margin-right: 0;color: rgba(68,61,68,0.98)">APHM: Learning Neural Parametric Head Models with 2D Adversarial Objectives</h3>
                            <h4 style="margin-top: 1.67em;margin-bottom: 1.67em;margin-left: 0;margin-right: 0;">Tathagata Bandyopadhyay</h4>
                            <h5 style="margin-top: 2.33em;margin-bottom: 2.33em;margin-left: 0;margin-right: 0;">Visual Computing Lab, Technical University of Munich</h5>
                            <h5 style="margin-top: 2.33em;margin-bottom: 2.33em;margin-left: 0;margin-right: 0;"><a href="#">code(coming soon)</a> | <a href="Bandyopadhyay_MA_Thesis_Final.pdf">MA Thesis PDF</a> | <a href="MA_Presentation_final_Tathagata.pdf">Slides</a></h5>
                <div><img src="identity_schematic_hr.png" id="flowchart_image" style="position:relative;margin: 1em auto;width: 75%;height: auto;padding: 0.5em"><figcaption>Identity model using Tri-plane based 3D representation</figcaption></div>
                <div><img src="expression_schematic.png" id="flowchart_image" style="position:relative;margin: 1em auto;width: 75%;height: auto;padding: 0.5em"><figcaption>Forward deformation field based expression model</figcaption></div><br><br>
                <h3><b>Abstract</b></b></h3>
                <div id="abstract" style="width:80%;font-family:Verdana;text-align:justify;padding:1em;position:relative;background:white;margin: 0 auto;">
                    Modeling human head is a long standing problem in computer graphics and has got many practical applications in computer games, animation and film industry. Parametric head models try to approach this problem by providing low dimensional and ideally disentangled control parameters to change the identity and expression of a human face without requiring to explicitly model each face and expression combination. While a simple PCA based parametric model can be easily obtained directly from the 3D face scans, such model is restricted to fixed template mesh topology and thus limited in capacity to represent high frequency details of any real face due to inherent linearity of the model. Recent progress in neural networks and neural implicit surface representation has enabled the computers to learn more complex parametric head models with better generalization capability. However, they still struggle to fit sparse and possibly noisy point-clouds or depth maps of real faces due to under constrained latent space. <br><br>
In this thesis, we propose to learn a neural parametric head model which utilizes 2D adversarial objective on multi-view differentiable renderings of 2D normal maps along side existing 3D point-cloud based objectives to properly constrain the latent spaces, thus enabling it to fit noisy point-clouds of real face scans. Additionally, we use tri-plane based hybrid neural surface representation to leverage its 3D aware rich features for representing high-frequency details and faster convergence. We empirically show that the proposed model not only out performs most of the existing models in reconstruction and fitting, but also is more robust to scanning noise. To our knowledge, we are the first to use tri-plane based hybrid surface representation in the context of neural parametric head models.
                </div>
                <br>
                <h3><b>Qualitative Results</b></h3><br>
                <div><video style="position:relative;margin: 1em auto;width: 75%;height: auto;padding: 0.5em" autoplay loop muted><source src="sota_identity_vis.mp4" type="video/mp4"/></video><figcaption>Identity reconstruction: proposed approach works better to reconstruct the hair regions.</figcaption></div>
                <div><video style="position:relative;margin: 1em auto;width: 75%;height: auto;padding: 0.5em" autoplay loop muted><source src="sota_exp_vis.mp4" type="video/mp4"/></video><figcaption>Expression reconstruction as neural forward deformation field.</figcaption></div>
                <div><img src="19_10_34_10.gif" style="position:relative;margin: 1em auto;width: 75%;height: auto;padding: 0.5em"><figcaption>Identity interpolation: Identity changes smoothly keeping expression unchanged</figcaption></div><br><br>
                <div><img src="32_1_10.gif" style="position:relative;margin: 1em auto;width: 75%;height: auto;padding: 0.5em"><figcaption>Expression interpolation: expression changes smoothly keeping the identity unchanged</figcaption></div>
                <br><h3><b>Ablation Study</b></h3><br>
                <div><img src="mat_ablation.PNG" style="position:relative;margin: 1em auto;width: 75%;height: auto;padding: 0.5em"><figcaption>Ablation study: as we can see both 2D and 3D objective functions complement each-other to produe more detailed face reconstruction </figcaption></div>
            </div>
        </div>
</html>
